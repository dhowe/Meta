<!DOCTYPE html 
    PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html><head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
  <title>Writing Digital Media | Main / EvolutionaryText</title>
  <link rel='stylesheet' href='pub/skins/print/print.css' type='text/css' />
  <!--HTMLHeader--><style type='text/css'><!--
  ul, ol, pre, dl, p { margin-top:0px; margin-bottom:0px; }
  code.escaped { white-space: nowrap; }
  .vspace { margin-top:1.33em; }
  .indent { margin-left:40px; }
  .outdent { margin-left:40px; text-indent:-40px; }
  a.createlinktext { text-decoration:none; border-bottom:1px dotted gray; }
  a.createlink { text-decoration:none; position:relative; top:-0.5em;
    font-weight:bold; font-size:smaller; border-bottom:none; }
  img { border:0px; }
  .editconflict { color:green; 
  font-style:italic; margin-top:1.33em; margin-bottom:1.33em; }

  table.markup { border:2px dotted #ccf; width:90%; }
  td.markup1, td.markup2 { padding-left:10px; padding-right:10px; }
  table.vert td.markup1 { border-bottom:1px solid #ccf; }
  table.horiz td.markup1 { width:23em; border-right:1px solid #ccf; }
  table.markup caption { text-align:left; }
  div.faq p, div.faq pre { margin-left:2em; }
  div.faq p.question { margin:1em 0 0.75em 0; font-weight:bold; }
  div.faqtoc div.faq * { display:none; }
  div.faqtoc div.faq p.question 
    { display:block; font-weight:normal; margin:0.5em 0 0.5em 20px; line-height:normal; }
  div.faqtoc div.faq p.question * { display:inline; }
   
    .frame 
      { border:1px solid #cccccc; padding:4px; background-color:#f9f9f9; }
    .lfloat { float:left; margin-right:0.5em; }
    .rfloat { float:right; margin-left:0.5em; }
a.varlink { text-decoration:none;}

--></style>  <meta name='robots' content='noindex,nofollow' />

</head>
<body>
  <div id='printhead'>
    <h3>From Writing Digital Media</h3>
    <h1 class='pagename'><a href='index.php-n=Main.HomePage.html'>Main: EvolutionaryText</a></h1>
  </div>
<!--PageText-->
<div id='wikitext'>
<p><br />
</p><h3>Project Ideas: Evolutionary algorithms and language</h3>
<p><br />
</p>
<div class='vspace'></div><hr />
<p class='vspace'>&nbsp;&nbsp;&nbsp;&nbsp;<strong>Claire Kwong</strong>
</p>
<div class='vspace'></div><div class='indent'>This project, like my final project idea, explores the shift from Web 1.0 forms of reading and writing to Web 2.0. The user can input a source text of a given (medium) length. The text will be displayed as the static wall of text it’s meant to be read as. From there, each word will be treated as a member of the population. The fitness function depends on how relevant the word is at the current time -- this will be evaluated by whether it appears on Twitter at the given time. For the initial population generation, words from the source text will “survive” - become unanchored from their original position, and start moving about - when someone tweets about it. After a specified duration of time, like 30 seconds, the rest of the text (that has not yet been tweeted about) disappears. Then the piece enters the mating stage. When words collide with each other, its child is determined by which word appears on Twitter first. The child word is picked from this tweet, excluding conjunctions like "is," etc. The parents die after a specified time, and words continue generating. Thus, the population evolves toward resembling the Twitter stream at the present moment. 
</div><div class='vspace'></div><hr />
<p class='vspace'>&nbsp;&nbsp;&nbsp;&nbsp;<strong>Fiona Condon</strong>
</p>
<div class='vspace'></div><div class='indent'>I’d like to use an evolutionary algorithm to “guess” an input word – have a text field for a single-word input into which the user would enter the word to be guessed. The initial population would be an array of randomly generated words. The program would start by generating a list of synonyms of the input word, and synonyms of synonyms, etc, so that it has a few lists which represent “depths” of similarity (a direct synonym would be in depth list 1, a synonym of a synonym in depth list 2, and so on). These pre-existing lists would enable the measure of fitness of a word. The process of “mating” words is not intuitive, but I imagine choosing a common synonym would be the best way, and, if not available, allowing the fitter parent to determine the word type of the child (whether it is a noun, adjective, whatever). This way, the appearance of a successful word guess in the array (that is, one which matches an entry in some depth level of the input), would at least influence the make-up of the words in terms of type. I’m not sure about the feasibility of this idea in terms of the time it would take to mate each word pair or the computational intensity of using Wordnet so heavily, but I’d like to at least explore the concept.
</div><div class='vspace'></div><hr />
<p class='vspace'>&nbsp;&nbsp;&nbsp;&nbsp;<strong>Miranda Steele</strong>
</p>
<div class='vspace'></div><div class='indent'>The project I would create using a genetic algorithm would be a black and white movie-creation algorithm. Each frame would be determined to have a certain fitness based on its similarity to any of a database of hands forming sign language; from frame to frame, 10% of the pixels would change. Once a certain fitness has been achieved, maybe 75-85%,  the goal would be instead to match a randomly generated image of noise. Similarly, when a certain fitness has been achieved, the fitness function would toggle back to the original function, causing the video produced to oscillate indefinitely between hazy forms of recognizable or unrecognizable signs and complete noise.
</div><div class='vspace'></div><hr />
<p class='vspace'>&nbsp;&nbsp;&nbsp;&nbsp;<strong>G.G.</strong>
</p>
<div class='vspace'></div><div class='indent'>This piece creates new and original works of poetry. Writers may submit an initial piece, and then the system evolves this text based on a fitness function which measures grammaticality and originality based on real-time corpus searches. The piece is a commentary on how people sometimes try to create something new just to create something new, where conceptualization and creation take a back seat, and originality is valued over content.
</div><div class='vspace'></div><hr />
<p class='vspace'>&nbsp;&nbsp;&nbsp;&nbsp;<strong>Thomas Etienne</strong>
</p>
<div class='vspace'></div><div class='indent'>In order to find the perfect quote evolutionary coding is used to develop NGrams. The evolution process finds the most common words with more than 4 letters and sentences with their use, used starting off the population pool. From there, the strongest, defined by their occurrence in the English language mate to become sentences/ mutations of their parents. In the mutation process, words can be added and subtracted depending on their occurrence in English, their length, their commonality and etymological relation to the parents. From the children, a new gen pool is created. This process is repeated until the majority of the population is the same sentence. With multiple iterations and comparison, deriving from the process we would find the perfect quote. 
</div><div class='vspace'></div><hr />
<p>&nbsp;&nbsp;&nbsp;&nbsp;<strong>Megan Hugdahl</strong>
</p>
<div class='vspace'></div><div class='indent'>This project explores the effects of mental illness on a population. Using statistics from the National Institute of Mental Health (highlighted <a class='urllink' href='http://cs.brown.edu/people/mhugdahl/cs195c/evoProject/ProjectData.txt' rel='nofollow'>here</a>), the initial population is assigned a diagnosis (or non-diagnosis), a random severity, and whether or not the individual has sought treatment. Based on this information, the "fittest" individuals are chosen to reproduce. Mental illness is surprisingly prevalent, considering how seldom it is discussed, and it is my hope that this piece sparks discussion not on just the Darwinian consequences of mental illness, but the costs and struggles of individuals in our society.
</div><div class='vspace'></div><hr />
<p class='vspace'>&nbsp;&nbsp;&nbsp;&nbsp;<strong>Jack Flintermann</strong>
</p>
<div class='vspace'></div><div class='indent'>My project attempts to come up with an optimal textual representation of “hotness” using Google face search (an option in their image search product that uses image processing to only return images containing a face) and hotornot.com (a website that allows the greater internet community to vote on the “hotness” of submitted pictures on a scale from 1 to 10). It does this by generating, selecting, and mutating textual descriptions. Each description consists of a series of n adjectives, where n can be experimentally adjusted. A set number of these are initially generated by a random sampling of dictionary adjectives. Each potential description is then prefiltered to ensure that a face search for that term returns at least 1 result. Then, at each iteration of the algorithm I use tournament selection to cull less “hot” results. This works by randomly selecting two descriptions from the pool, performing a face search for each, and returning the top results. If a query returns no results, it is always removed from the pool. Once both images have been retrieved, they are uploaded to hotornot.com and monitored until they have obtained 500 votes. Whichever image is voted to be “hotter” survives and the other is removed from the pool. This leaves a pool of survivors of at most half the size of the original pool. Then, two randomly selected descriptions are mated by combining subsets of their adjectives into a new description. Recombination is used to combine adjacent words from each parent (to handle cases where multiple words are hot together but not individually). Each new description is then mutated where each of its word may be randomly chosen to be replaced by a synonym (with low probability) or a randomly generated dictionary adjective (with very low probability). Finally, like the initial results, it is prefiltered to see if it returns any face results. This mating/mutation/prefiltering process continues until the pool of descriptions reaches its original size. After running this program for several thousand iterations, one hopes to obtain the ideal textual description of hotness as judged by the broader Internet community as well as Google’s ability to translate text to image.
</div><div class='vspace'></div><hr />
<p class='vspace'><br />
</p>
<div class='vspace'></div>
</div>

  <div id='printfoot'>
    <div class='from'>Retrieved from https://rednoise.org/teaching/wdm/index.php?n=Main.EvolutionaryText</div>
    <div class='lastmod'>Page last modified on November 29, 2010, at 09:31 PM EST</div></div>
<!--HTMLFooter-->
</body>
</html>
