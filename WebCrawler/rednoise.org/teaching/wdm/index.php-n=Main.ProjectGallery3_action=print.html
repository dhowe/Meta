<!DOCTYPE html 
    PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html><head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
  <title>Writing Digital Media | Main / ProjectGallery3</title>
  <link rel='stylesheet' href='pub/skins/print/print.css' type='text/css' />
  <!--HTMLHeader--><style type='text/css'><!--
  ul, ol, pre, dl, p { margin-top:0px; margin-bottom:0px; }
  code.escaped { white-space: nowrap; }
  .vspace { margin-top:1.33em; }
  .indent { margin-left:40px; }
  .outdent { margin-left:40px; text-indent:-40px; }
  a.createlinktext { text-decoration:none; border-bottom:1px dotted gray; }
  a.createlink { text-decoration:none; position:relative; top:-0.5em;
    font-weight:bold; font-size:smaller; border-bottom:none; }
  img { border:0px; }
  .editconflict { color:green; 
  font-style:italic; margin-top:1.33em; margin-bottom:1.33em; }

  table.markup { border:2px dotted #ccf; width:90%; }
  td.markup1, td.markup2 { padding-left:10px; padding-right:10px; }
  table.vert td.markup1 { border-bottom:1px solid #ccf; }
  table.horiz td.markup1 { width:23em; border-right:1px solid #ccf; }
  table.markup caption { text-align:left; }
  div.faq p, div.faq pre { margin-left:2em; }
  div.faq p.question { margin:1em 0 0.75em 0; font-weight:bold; }
  div.faqtoc div.faq * { display:none; }
  div.faqtoc div.faq p.question 
    { display:block; font-weight:normal; margin:0.5em 0 0.5em 20px; line-height:normal; }
  div.faqtoc div.faq p.question * { display:inline; }
   
    .frame 
      { border:1px solid #cccccc; padding:4px; background-color:#f9f9f9; }
    .lfloat { float:left; margin-right:0.5em; }
    .rfloat { float:right; margin-left:0.5em; }
a.varlink { text-decoration:none;}

--></style>  <meta name='robots' content='noindex,nofollow' />

</head>
<body>
  <div id='printhead'>
    <h3>From Writing Digital Media</h3>
    <h1 class='pagename'><a href='index.php-n=Main.HomePage.html'>Main: ProjectGallery3</a></h1>
  </div>
<!--PageText-->
<div id='wikitext'>
<h2>Pairs Projects</h2>
<p class='vspace'><br />
<strong>Andrew &amp; Sebastian: </strong>
</p>
<p class='vspace'>Honest TV
</p>
<div class='vspace'></div><div class='img imgonly'><img src='http://www.alloysoftware.com/pdal/htv/s_image1s.jpg' alt='' title='' /></div>
<p class='vspace'><a class='urllink' href='http://www.alloysoftware.com/pdal/htv/' rel='nofollow'>&gt;&gt; Project Site (Updated)</a>
</p>
<p class='vspace'><strong>Clement &amp; Justin: </strong>
</p>
<p class='vspace'>Yelling at a Wall
</p>
<div class='vspace'></div><div class='img imgonly'><img src='http://plantarchy.us/katko/processing/yelling-at-a-wall/images/applet-visual.png' alt='' title='' /></div>
<p class='vspace'><a class='urllink' href='http://plantarchy.us/katko/processing/yelling-at-a-wall/' rel='nofollow'>&gt;&gt; Project Site</a>
</p>
<p class='vspace'><strong>Caleb &amp; Chuan: </strong>
</p>
<p class='vspace'><strong>Text Chorus</strong>
</p>
<div class='vspace'></div><div class='img imgonly'><img src='http://dm.risd.edu/~akhoo/pdal/textchorus.jpg' alt='' title='' /></div>
<p class='vspace'>A chorus of synthesized voices combine with a generative audio algorithm to call out, in unison, what they were just fed with. 
</p>
<p class='vspace'>The words that the voices read play into a larger sound work, where the simultaneity of music is applied to the linearity of text. Combined with the synthesized voices the words themselves will be further extended into an arpeggiated 'chord'.
</p>
<p class='vspace'>Keywords are extracted from Wikipedia, specifically a locally-saved Wikipedia database created via the DBPedia.org datasets. The algorithm knows of only a single starting point – a Wikipedia page titled "Collective consciousness". The algorithm always attempts to navigate across and away from its origin, and it is impossible to tell where the voices will take you.
</p>
<p class='vspace'>The algorithm operates without prejudice or bias on any subject, but left on its own one begins to see some emergent patterns in the way it navigates the Wikipedia terrain.
</p>
<p class='vspace'><a class='urllink' href='http://textchorus.googlecode.com' rel='nofollow'>&gt;&gt; Google Code Project Page</a>
</p>
<p class='vspace'>Final Ititeration:
<a class='urllink' href='http://projects.caleblarsen.com/textchorus/src/' rel='nofollow'>&gt;&gt; Source Code</a>
<a class='urllink' href='http://projects.caleblarsen.com/textchorus/application.macosx' rel='nofollow'>&gt;&gt; Mac OS X Application</a>
<a class='urllink' href='http://projects.caleblarsen.com/textchorus/application.windows' rel='nofollow'>&gt;&gt; Windows Application</a>
<a class='urllink' href='http://projects.caleblarsen.com/textchorus/application.linux' rel='nofollow'>&gt;&gt; Linux Applicaion</a>
</p>
<p class='vspace'><strong>Mary and Jenny: </strong>
</p><div class='img imgonly'><img src='http://dm.risd.edu/~mchoueiter/pdal/SoundSpace/material/snapshot.png' alt='' title='' /></div>
<p class='vspace'><a class='urllink' href='http://dm.risd.edu/~mchoueiter/pdal/SoundSpace/index.php' rel='nofollow'>"Sound Space" Project Page</a>
</p>
<p class='vspace'>This piece directly links body motion in a space to the sound created within that space. Body language and movement affect the pitch, volume, and speed of real-time captured sound, the newly altered form of which is then replayed into the space. Our work thus apprehends sound and the speaking silence of body language to illustrate the ways our actions affect the space we are in.
</p>
<p class='vspace'><strong>Jeremy and Angela: </strong>
</p>
<div class='vspace'></div><div class='img imgonly'><img src='http://s3.amazonaws.com/shoes_code/hacks/squid.jpg' alt='' title='' /></div>
<p class='vspace'><a class='urllink' href='http://fiercefrontiers.com/applets/hawking/' rel='nofollow'>"A Face for Stephen Hawking" Project Page</a>
</p>
<p class='vspace'><strong>Matt and Christina</strong>
</p><div class='img imgonly'><a class='urllink' href='http://mjacobs.net/pdal/helloworld/blog_ss.png' rel='nofollow'><img src='http://mjacobs.net/pdal/helloworld/blog_ss_thumb.png' alt='' /></a></div>
<p class='vspace'>In a technologically motivated world, our computers have become so complex, and so completely integrated into our lives, that they have become active participants in our day-to-day existence. As this relationship evolves, our interactions with our computers become more and more like our interactions with other humans. We speak to our computers, attempt to establish dialog with them, and our lives come to a crashing halt when our computers have a problem we cannot solve.
</p>
<p class='vspace'>However, though we have begun to treat our computers almost as individual, sentient beings, they cannot interact with us. The computer's responses are limited by its functionality. But the computer itself knows what it is doing. Our computers keep very detailed logs of system, user, and server information. In our project, we wanted to present the computer interacting with the world as a human would by allowing it to share its daily activities through a blog.
</p>
<p class='vspace'>In this way, we create a human outlet for the activities of machines which have become complex enough that these activities would otherwise be obfuscated and difficult to comprehend and make sense of. We allow the computer to engage with the user, and to become an active participant in the dialog of social networks for which it has previously served only as a tool. 
</p>
<p class='vspace'><a class='urllink' href='http://mjacobs.net/pdal/helloworld/' rel='nofollow'>"Hello World!" Project Page</a>
</p>
<p class='vspace'><strong>Chris and Donko</strong>
</p>
<div class='vspace'></div><div class='img imgonly'><img src='http://dm.risd.edu/~djeliazkov/CS1950/Aurenvi/aurenvi.jpg' alt='' title='' /></div>
<p class='vspace'>Project <strong>Aurenvi</strong> analyzes a sound file and extrapolates key information about that specific file, such as beats, tempo, timbre, pitch, frequency and other audio characteristics.  Using such parameters as inputs, a world is generated that is unique to the contents of that music file. The world can be very abstract in nature, although there would be certain rules that govern its creation from start to finish. Simple shapes such as squares and circles can be transformed and manipulated to generate more complex structures, with the end resulting being an interesting and hopefully beautiful image. We considered several libraries that have already been created to help us analyze audio files, with the most promising being <a class='urllink' href='http://www.echonest.com' rel='nofollow'>http://www.echonest.com</a>. 
</p>
<p class='vspace'>Update: Grammar is used to generate an organism. The music analysis provides the background environment and the behavior of the organism.
</p>
<p class='vspace'><strong>Project web site:</strong> <a class='urllink' href='http://dm.risd.edu/~djeliazkov/CS1950/Aurenvi' rel='nofollow'>Aurenvi</a>
</p>
<div class='vspace'></div>
</div>

  <div id='printfoot'>
    <div class='from'>Retrieved from https://rednoise.org/teaching/wdm/index.php?n=Main.ProjectGallery3</div>
    <div class='lastmod'>Page last modified on May 16, 2008, at 10:35 PM EST</div></div>
<!--HTMLFooter-->
</body>
</html>
